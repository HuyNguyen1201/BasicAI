{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhKacG-n8_sH"
      },
      "source": [
        "# Image classification via fine-tuning with EfficientNet\n",
        "\n",
        "**Author:** [Yixing Fu](https://github.com/yixingfu)<br>\n",
        "**Date created:** 2020/06/30<br>\n",
        "**Last modified:** 2020/07/16<br>\n",
        "**Description:** Use EfficientNet with weights pre-trained on imagenet for Stanford Dogs classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqO7QtsS8_sL"
      },
      "source": [
        "## Introduction: what is EfficientNet\n",
        "\n",
        "EfficientNet, first introduced in [Tan and Le, 2019](https://arxiv.org/abs/1905.11946)\n",
        "is among the most efficient models (i.e. requiring least FLOPS for inference)\n",
        "that reaches State-of-the-Art accuracy on both\n",
        "imagenet and common image classification transfer learning tasks.\n",
        "\n",
        "The smallest base model is similar to [MnasNet](https://arxiv.org/abs/1807.11626), which\n",
        "reached near-SOTA with a significantly smaller model. By introducing a heuristic way to\n",
        "scale the model, EfficientNet provides a family of models (B0 to B7) that represents a\n",
        "good combination of efficiency and accuracy on a variety of scales. Such a scaling\n",
        "heuristics (compound-scaling, details see\n",
        "[Tan and Le, 2019](https://arxiv.org/abs/1905.11946)) allows the\n",
        "efficiency-oriented base model (B0) to surpass models at every scale, while avoiding\n",
        "extensive grid-search of hyperparameters.\n",
        "\n",
        "A summary of the latest updates on the model is available at\n",
        "[here](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet), where various\n",
        "augmentation schemes and semi-supervised learning approaches are applied to further\n",
        "improve the imagenet performance of the models. These extensions of the model can be used\n",
        "by updating weights without changing model architecture.\n",
        "\n",
        "## B0 to B7 variants of EfficientNet\n",
        "\n",
        "*(This section provides some details on \"compound scaling\", and can be skipped\n",
        "if you're only interested in using the models)*\n",
        "\n",
        "Based on the [original paper](https://arxiv.org/abs/1905.11946) people may have the\n",
        "impression that EfficientNet is a continuous family of models created by arbitrarily\n",
        "choosing scaling factor in as Eq.(3) of the paper.  However, choice of resolution,\n",
        "depth and width are also restricted by many factors:\n",
        "\n",
        "- Resolution: Resolutions not divisible by 8, 16, etc. cause zero-padding near boundaries\n",
        "of some layers which wastes computational resources. This especially applies to smaller\n",
        "variants of the model, hence the input resolution for B0 and B1 are chosen as 224 and\n",
        "240.\n",
        "\n",
        "- Depth and width: The building blocks of EfficientNet demands channel size to be\n",
        "multiples of 8.\n",
        "\n",
        "- Resource limit: Memory limitation may bottleneck resolution when depth\n",
        "and width can still increase. In such a situation, increasing depth and/or\n",
        "width but keep resolution can still improve performance.\n",
        "\n",
        "As a result, the depth, width and resolution of each variant of the EfficientNet models\n",
        "are hand-picked and proven to produce good results, though they may be significantly\n",
        "off from the compound scaling formula.\n",
        "Therefore, the keras implementation (detailed below) only provide these 8 models, B0 to B7,\n",
        "instead of allowing arbitray choice of width / depth / resolution parameters.\n",
        "\n",
        "## Keras implementation of EfficientNet\n",
        "\n",
        "An implementation of EfficientNet B0 to B7 has been shipped with tf.keras since TF2.3. To\n",
        "use EfficientNetB0 for classifying 1000 classes of images from imagenet, run:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "model = EfficientNetB0(weights='imagenet')\n",
        "```\n",
        "\n",
        "This model takes input images of shape (224, 224, 3), and the input data should range\n",
        "[0, 255]. Normalization is included as part of the model.\n",
        "\n",
        "Because training EfficientNet on ImageNet takes a tremendous amount of resources and\n",
        "several techniques that are not a part of the model architecture itself. Hence the Keras\n",
        "implementation by default loads pre-trained weights obtained via training with\n",
        "[AutoAugment](https://arxiv.org/abs/1805.09501).\n",
        "\n",
        "For B0 to B7 base models, the input shapes are different. Here is a list of input shape\n",
        "expected for each model:\n",
        "\n",
        "| Base model | resolution|\n",
        "|----------------|-----|\n",
        "| EfficientNetB0 | 224 |\n",
        "| EfficientNetB1 | 240 |\n",
        "| EfficientNetB2 | 260 |\n",
        "| EfficientNetB3 | 300 |\n",
        "| EfficientNetB4 | 380 |\n",
        "| EfficientNetB5 | 456 |\n",
        "| EfficientNetB6 | 528 |\n",
        "| EfficientNetB7 | 600 |\n",
        "\n",
        "When the model is intended for transfer learning, the Keras implementation\n",
        "provides a option to remove the top layers:\n",
        "```\n",
        "model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "```\n",
        "This option excludes the final `Dense` layer that turns 1280 features on the penultimate\n",
        "layer into prediction of the 1000 ImageNet classes. Replacing the top layer with custom\n",
        "layers allows using EfficientNet as a feature extractor in a transfer learning workflow.\n",
        "\n",
        "Another argument in the model constructor worth noticing is `drop_connect_rate` which controls\n",
        "the dropout rate responsible for [stochastic depth](https://arxiv.org/abs/1603.09382).\n",
        "This parameter serves as a toggle for extra regularization in finetuning, but does not\n",
        "affect loaded weights. For example, when stronger regularization is desired, try:\n",
        "\n",
        "```python\n",
        "model = EfficientNetB0(weights='imagenet', drop_connect_rate=0.4)\n",
        "```\n",
        "The default value is 0.2.\n",
        "\n",
        "## Example: EfficientNetB0 for Stanford Dogs.\n",
        "\n",
        "EfficientNet is capable of a wide range of image classification tasks.\n",
        "This makes it a good model for transfer learning.\n",
        "As an end-to-end example, we will show using pre-trained EfficientNetB0 on\n",
        "[Stanford Dogs](http://vision.stanford.edu/aditya86/ImageNetDogs/main.html) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SO9_E1xY8_sO"
      },
      "outputs": [],
      "source": [
        "# IMG_SIZE is determined by EfficientNet model choice\n",
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5t25uYs8_sP"
      },
      "source": [
        "## Setup and data loading\n",
        "\n",
        "This example requires TensorFlow 2.3 or above.\n",
        "\n",
        "To use TPU, the TPU runtime must match current running TensorFlow\n",
        "version. If there is a mismatch, try:\n",
        "\n",
        "```python\n",
        "from cloud_tpu_client import Client\n",
        "c = Client()\n",
        "c.configure_tpu_version(tf.__version__, restart_type=\"always\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kPwAe_hQ8_sQ",
        "outputId": "1c68f832-fe09-4876-fcd7-79b3914ab24b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.52.60.162:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.52.60.162:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: grpc://10.52.60.162:8470\n",
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
        "    strategy = tf.distribute.MirroredStrategy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dslSRec58_sQ"
      },
      "source": [
        "### Loading data\n",
        "\n",
        "Here we load data from [tensorflow_datasets](https://www.tensorflow.org/datasets)\n",
        "(hereafter TFDS).\n",
        "Stanford Dogs dataset is provided in\n",
        "TFDS as [stanford_dogs](https://www.tensorflow.org/datasets/catalog/stanford_dogs).\n",
        "It features 20,580 images that belong to 120 classes of dog breeds\n",
        "(12,000 for training and 8,580 for testing).\n",
        "\n",
        "By simply changing `dataset_name` below, you may also try this notebook for\n",
        "other datasets in TFDS such as\n",
        "[cifar10](https://www.tensorflow.org/datasets/catalog/cifar10),\n",
        "[cifar100](https://www.tensorflow.org/datasets/catalog/cifar100),\n",
        "[food101](https://www.tensorflow.org/datasets/catalog/food101),\n",
        "etc. When the images are much smaller than the size of EfficientNet input,\n",
        "we can simply upsample the input images. It has been shown in\n",
        "[Tan and Le, 2019](https://arxiv.org/abs/1905.11946) that transfer learning\n",
        "result is better for increased resolution even if input images remain small.\n",
        "\n",
        "For TPU: if using TFDS datasets,\n",
        "a [GCS bucket](https://cloud.google.com/storage/docs/key-terms#buckets)\n",
        "location is required to save the datasets. For example:\n",
        "\n",
        "```python\n",
        "tfds.load(dataset_name, data_dir=\"gs://example-bucket/datapath\")\n",
        "```\n",
        "\n",
        "Also, both the current environment and the TPU service account have\n",
        "proper [access](https://cloud.google.com/tpu/docs/storage-buckets#authorize_the_service_account)\n",
        "to the bucket. Alternatively, for small datasets you may try loading data\n",
        "into the memory and use `tf.data.Dataset.from_tensor_slices()`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tfds-nightly tensorflow matplotlib "
      ],
      "metadata": {
        "id": "1hm9MpD_-_eb",
        "outputId": "357dbcde-b2e9-40f0-8ea5-67a2bf9d602b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.1 MB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool"
      ],
      "metadata": {
        "id": "pyzmvoPT_C58",
        "outputId": "b8934f16-2e07-419a-ed3b-0ff6fa1a02b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 1.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HuyNguyen1201/datasets_tensorflow.git"
      ],
      "metadata": {
        "id": "zgg4s-ij_EjQ",
        "outputId": "3df872e2-c473-4be7-dc1d-87182088e472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets_tensorflow'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 20 (delta 3), reused 13 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd my_dataset/"
      ],
      "metadata": {
        "id": "2ntK5t64_Yty",
        "outputId": "aacda5b9-de5c-494f-aa08-2c05b7b4e5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/my_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tfds build --overwrite"
      ],
      "metadata": {
        "id": "h1RbSFTS_eif",
        "outputId": "3ac97acd-befb-45ec-8789-a868508c04c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-07 19:55:58.887261: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "INFO[build.py]: Loading dataset  from path: /content/my_dataset/my_dataset.py\n",
            "INFO[build.py]: download_and_prepare for dataset my_dataset/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset my_dataset (/root/tensorflow_datasets/my_dataset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/my_dataset/1.0.0...\u001b[0m\n",
            "patool: Extracting dataset.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/my_dataset/dataset.rar\n",
            "patool:     with cwd='dataset'\n",
            "patool: ... dataset.rar extracted to `dataset'.\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train examples...: 295 examples [00:00, 2941.13 examples/s]\u001b[A\n",
            "Generating train examples...: 590 examples [00:00, 2831.29 examples/s]\u001b[A\n",
            "Generating train examples...: 874 examples [00:00, 2777.58 examples/s]\u001b[A\n",
            "Generating train examples...: 1152 examples [00:00, 2732.35 examples/s]\u001b[A\n",
            "Generating train examples...: 1457 examples [00:00, 2840.78 examples/s]\u001b[A\n",
            "Generating train examples...: 1768 examples [00:00, 2926.39 examples/s]\u001b[A\n",
            "Generating train examples...: 2079 examples [00:00, 2985.05 examples/s]\u001b[A\n",
            "Generating train examples...: 2378 examples [00:00, 2938.03 examples/s]\u001b[A\n",
            "Generating train examples...: 2678 examples [00:00, 2955.55 examples/s]\u001b[A\n",
            "Generating train examples...: 2999 examples [00:01, 3032.90 examples/s]\u001b[A\n",
            "Generating train examples...: 3335 examples [00:01, 3131.71 examples/s]\u001b[A\n",
            "Generating train examples...: 3649 examples [00:01, 3039.55 examples/s]\u001b[A\n",
            "Generating train examples...: 3954 examples [00:01, 2906.59 examples/s]\u001b[A\n",
            "Generating train examples...: 4247 examples [00:01, 2585.49 examples/s]\u001b[A\n",
            "Generating train examples...: 4526 examples [00:01, 2638.83 examples/s]\u001b[A\n",
            "Generating train examples...: 4824 examples [00:01, 2731.50 examples/s]\u001b[A\n",
            "Generating train examples...: 5102 examples [00:01, 2714.61 examples/s]\u001b[A\n",
            "Generating train examples...: 5397 examples [00:01, 2780.97 examples/s]\u001b[A\n",
            "Generating train examples...: 5726 examples [00:01, 2927.37 examples/s]\u001b[A\n",
            "Generating train examples...: 6023 examples [00:02, 2937.85 examples/s]\u001b[A\n",
            "Generating train examples...: 6319 examples [00:02, 2935.40 examples/s]\u001b[A\n",
            "Generating train examples...: 6614 examples [00:02, 2835.63 examples/s]\u001b[A\n",
            "Generating train examples...: 6938 examples [00:02, 2952.00 examples/s]\u001b[A\n",
            "Generating train examples...: 7262 examples [00:02, 3034.81 examples/s]\u001b[A\n",
            "Generating train examples...: 7628 examples [00:02, 3217.89 examples/s]\u001b[A\n",
            "Generating train examples...: 7951 examples [00:02, 3164.26 examples/s]\u001b[A\n",
            "Generating train examples...: 8269 examples [00:02, 3149.27 examples/s]\u001b[A\n",
            "Generating train examples...: 8587 examples [00:02, 3157.46 examples/s]\u001b[A\n",
            "Generating train examples...: 8904 examples [00:03, 2987.25 examples/s]\u001b[A\n",
            "Generating train examples...: 9262 examples [00:03, 3154.91 examples/s]\u001b[A\n",
            "Generating train examples...: 9601 examples [00:03, 3222.42 examples/s]\u001b[A\n",
            "Generating train examples...: 9926 examples [00:03, 3095.47 examples/s]\u001b[A\n",
            "Generating train examples...: 10250 examples [00:03, 3134.23 examples/s]\u001b[A\n",
            "Generating train examples...: 10579 examples [00:03, 3178.51 examples/s]\u001b[A\n",
            "Generating train examples...: 10899 examples [00:03, 3081.81 examples/s]\u001b[A\n",
            "Generating train examples...: 11210 examples [00:03, 3088.20 examples/s]\u001b[A\n",
            "Generating train examples...: 11520 examples [00:03, 3034.11 examples/s]\u001b[A\n",
            "Generating train examples...: 11825 examples [00:03, 2994.48 examples/s]\u001b[A\n",
            "Generating train examples...: 12128 examples [00:04, 3002.62 examples/s]\u001b[A\n",
            "Generating train examples...: 12431 examples [00:04, 3007.87 examples/s]\u001b[A\n",
            "Generating train examples...: 12733 examples [00:04, 2898.45 examples/s]\u001b[A\n",
            "Generating train examples...: 13048 examples [00:04, 2970.66 examples/s]\u001b[A\n",
            "Generating train examples...: 13349 examples [00:04, 2981.34 examples/s]\u001b[A\n",
            "Generating train examples...: 13648 examples [00:04, 2893.99 examples/s]\u001b[A\n",
            "Generating train examples...: 13939 examples [00:04, 2895.81 examples/s]\u001b[A\n",
            "Generating train examples...: 14261 examples [00:04, 2990.08 examples/s]\u001b[A\n",
            "Generating train examples...: 14568 examples [00:04, 3013.30 examples/s]\u001b[A\n",
            "Generating train examples...: 14914 examples [00:05, 3142.42 examples/s]\u001b[A\n",
            "Generating train examples...: 15231 examples [00:05, 3150.03 examples/s]\u001b[A\n",
            "Generating train examples...: 15569 examples [00:05, 3217.34 examples/s]\u001b[A\n",
            "Generating train examples...: 15892 examples [00:05, 3083.24 examples/s]\u001b[A\n",
            "Generating train examples...: 16202 examples [00:05, 3045.85 examples/s]\u001b[A\n",
            "Generating train examples...: 16513 examples [00:05, 3063.27 examples/s]\u001b[A\n",
            "Generating train examples...: 16821 examples [00:05, 3057.81 examples/s]\u001b[A\n",
            "Generating train examples...: 17187 examples [00:05, 3234.27 examples/s]\u001b[A\n",
            "Generating train examples...: 17512 examples [00:05, 3176.75 examples/s]\u001b[A\n",
            "Generating train examples...: 17831 examples [00:05, 3088.92 examples/s]\u001b[A\n",
            "Generating train examples...: 18141 examples [00:06, 3082.10 examples/s]\u001b[A\n",
            "Generating train examples...: 18450 examples [00:06, 3043.50 examples/s]\u001b[A\n",
            "Generating train examples...: 18755 examples [00:06, 2969.47 examples/s]\u001b[A\n",
            "Generating train examples...: 19053 examples [00:06, 2656.99 examples/s]\u001b[A\n",
            "Generating train examples...: 19325 examples [00:06, 2529.14 examples/s]\u001b[A\n",
            "Generating train examples...: 19643 examples [00:06, 2701.46 examples/s]\u001b[A\n",
            "Generating train examples...: 19919 examples [00:06, 2705.33 examples/s]\u001b[A\n",
            "Generating train examples...: 20239 examples [00:06, 2844.43 examples/s]\u001b[A\n",
            "Generating train examples...: 20528 examples [00:06, 2850.98 examples/s]\u001b[A\n",
            "Generating train examples...: 20816 examples [00:07, 2732.48 examples/s]\u001b[A\n",
            "Generating train examples...: 21108 examples [00:07, 2783.60 examples/s]\u001b[A\n",
            "Generating train examples...: 21420 examples [00:07, 2879.64 examples/s]\u001b[A\n",
            "Generating train examples...: 21710 examples [00:07, 2875.85 examples/s]\u001b[A\n",
            "Generating train examples...: 21999 examples [00:07, 2804.34 examples/s]\u001b[A\n",
            "Generating train examples...: 22287 examples [00:07, 2824.88 examples/s]\u001b[A\n",
            "Generating train examples...: 22630 examples [00:07, 3001.43 examples/s]\u001b[A\n",
            "Generating train examples...: 22961 examples [00:07, 3090.75 examples/s]\u001b[A\n",
            "Generating train examples...: 23271 examples [00:07, 3065.52 examples/s]\u001b[A\n",
            "Generating train examples...: 23588 examples [00:07, 3095.38 examples/s]\u001b[A\n",
            "Generating train examples...: 23910 examples [00:08, 3128.90 examples/s]\u001b[A\n",
            "Generating train examples...: 24239 examples [00:08, 3174.14 examples/s]\u001b[A\n",
            "Generating train examples...: 24607 examples [00:08, 3324.09 examples/s]\u001b[A\n",
            "Generating train examples...: 24957 examples [00:08, 3374.51 examples/s]\u001b[A\n",
            "Generating train examples...: 25301 examples [00:08, 3393.67 examples/s]\u001b[A\n",
            "Generating train examples...: 25641 examples [00:08, 3312.11 examples/s]\u001b[A\n",
            "Generating train examples...: 25973 examples [00:08, 3197.34 examples/s]\u001b[A\n",
            "Generating train examples...: 26312 examples [00:08, 3252.06 examples/s]\u001b[A\n",
            "Generating train examples...: 26639 examples [00:08, 3213.32 examples/s]\u001b[A\n",
            "Generating train examples...: 26962 examples [00:08, 3172.42 examples/s]\u001b[A\n",
            "Generating train examples...: 27283 examples [00:09, 3183.30 examples/s]\u001b[A\n",
            "Generating train examples...: 27602 examples [00:09, 3116.91 examples/s]\u001b[A\n",
            "Generating train examples...: 27915 examples [00:09, 3006.93 examples/s]\u001b[A\n",
            "Generating train examples...: 28237 examples [00:09, 3065.78 examples/s]\u001b[A\n",
            "Generating train examples...: 28545 examples [00:09, 3051.44 examples/s]\u001b[A\n",
            "Generating train examples...: 28851 examples [00:09, 2885.68 examples/s]\u001b[A\n",
            "Generating train examples...: 29146 examples [00:09, 2903.62 examples/s]\u001b[A\n",
            "Generating train examples...: 29449 examples [00:09, 2931.72 examples/s]\u001b[A\n",
            "Generating train examples...: 29744 examples [00:09, 2848.13 examples/s]\u001b[A\n",
            "Generating train examples...: 30070 examples [00:10, 2962.87 examples/s]\u001b[A\n",
            "Generating train examples...: 30412 examples [00:10, 3093.58 examples/s]\u001b[A\n",
            "Generating train examples...: 30723 examples [00:10, 3025.06 examples/s]\u001b[A\n",
            "Generating train examples...: 31027 examples [00:10, 3028.70 examples/s]\u001b[A\n",
            "Generating train examples...: 31331 examples [00:10, 2955.17 examples/s]\u001b[A\n",
            "Generating train examples...: 31628 examples [00:10, 2900.00 examples/s]\u001b[A\n",
            "Generating train examples...: 31934 examples [00:10, 2945.29 examples/s]\u001b[A\n",
            "Generating train examples...: 32230 examples [00:10, 2902.94 examples/s]\u001b[A\n",
            "Generating train examples...: 32567 examples [00:10, 3037.71 examples/s]\u001b[A\n",
            "Generating train examples...: 32894 examples [00:10, 3104.71 examples/s]\u001b[A\n",
            "Generating train examples...: 33217 examples [00:11, 3140.81 examples/s]\u001b[A\n",
            "Generating train examples...: 33547 examples [00:11, 3185.56 examples/s]\u001b[A\n",
            "Generating train examples...: 33883 examples [00:11, 3236.68 examples/s]\u001b[A\n",
            "Generating train examples...: 34207 examples [00:11, 2761.42 examples/s]\u001b[A\n",
            "Generating train examples...: 34496 examples [00:11, 2688.60 examples/s]\u001b[A\n",
            "Generating train examples...: 34776 examples [00:11, 2716.89 examples/s]\u001b[A\n",
            "Generating train examples...: 35089 examples [00:11, 2829.62 examples/s]\u001b[A\n",
            "Generating train examples...: 35378 examples [00:11, 2794.96 examples/s]\u001b[A\n",
            "Generating train examples...: 35667 examples [00:11, 2819.48 examples/s]\u001b[A\n",
            "Generating train examples...: 35994 examples [00:12, 2948.90 examples/s]\u001b[A\n",
            "Generating train examples...: 36315 examples [00:12, 3022.12 examples/s]\u001b[A\n",
            "Generating train examples...: 36620 examples [00:12, 2900.37 examples/s]\u001b[A\n",
            "Generating train examples...: 36913 examples [00:12, 2859.18 examples/s]\u001b[A\n",
            "Generating train examples...: 37236 examples [00:12, 2965.56 examples/s]\u001b[A\n",
            "Generating train examples...: 37552 examples [00:12, 3020.06 examples/s]\u001b[A\n",
            "Generating train examples...: 37856 examples [00:12, 2988.88 examples/s]\u001b[A\n",
            "Generating train examples...: 38156 examples [00:12, 2884.75 examples/s]\u001b[A\n",
            "Generating train examples...: 38446 examples [00:12, 2774.26 examples/s]\u001b[A\n",
            "Generating train examples...: 38725 examples [00:13, 2740.62 examples/s]\u001b[A\n",
            "Generating train examples...: 39000 examples [00:13, 2695.40 examples/s]\u001b[A\n",
            "Generating train examples...: 39271 examples [00:13, 2692.78 examples/s]\u001b[A\n",
            "Generating train examples...: 39580 examples [00:13, 2805.88 examples/s]\u001b[A\n",
            "Generating train examples...: 39905 examples [00:13, 2931.83 examples/s]\u001b[A\n",
            "Generating train examples...: 40199 examples [00:13, 2854.15 examples/s]\u001b[A\n",
            "Generating train examples...: 40530 examples [00:13, 2982.05 examples/s]\u001b[A\n",
            "Generating train examples...: 40830 examples [00:13, 2973.63 examples/s]\u001b[A\n",
            "Generating train examples...: 41129 examples [00:13, 2933.11 examples/s]\u001b[A\n",
            "Generating train examples...: 41423 examples [00:13, 2862.23 examples/s]\u001b[A\n",
            "Generating train examples...: 41710 examples [00:14, 2760.83 examples/s]\u001b[A\n",
            "Generating train examples...: 41988 examples [00:14, 2753.12 examples/s]\u001b[A\n",
            "Generating train examples...: 42296 examples [00:14, 2846.68 examples/s]\u001b[A\n",
            "Generating train examples...: 42628 examples [00:14, 2983.55 examples/s]\u001b[A\n",
            "Generating train examples...: 42973 examples [00:14, 3120.36 examples/s]\u001b[A\n",
            "Generating train examples...: 43301 examples [00:14, 3165.65 examples/s]\u001b[A\n",
            "Generating train examples...: 43625 examples [00:14, 3185.24 examples/s]\u001b[A\n",
            "Generating train examples...: 43945 examples [00:14, 2796.12 examples/s]\u001b[A\n",
            "Generating train examples...: 44247 examples [00:14, 2856.02 examples/s]\u001b[A\n",
            "Generating train examples...: 44540 examples [00:15, 2855.79 examples/s]\u001b[A\n",
            "Generating train examples...: 44847 examples [00:15, 2916.38 examples/s]\u001b[A\n",
            "Generating train examples...: 45143 examples [00:15, 2906.69 examples/s]\u001b[A\n",
            "Generating train examples...: 45437 examples [00:15, 2894.09 examples/s]\u001b[A\n",
            "Generating train examples...: 45742 examples [00:15, 2938.28 examples/s]\u001b[A\n",
            "Generating train examples...: 46038 examples [00:15, 2921.87 examples/s]\u001b[A\n",
            "Generating train examples...: 46332 examples [00:15, 2898.37 examples/s]\u001b[A\n",
            "Generating train examples...: 46623 examples [00:15, 2822.28 examples/s]\u001b[A\n",
            "Generating train examples...: 46907 examples [00:15, 2811.61 examples/s]\u001b[A\n",
            "Generating train examples...: 47223 examples [00:15, 2913.09 examples/s]\u001b[A\n",
            "Generating train examples...: 47528 examples [00:16, 2951.31 examples/s]\u001b[A\n",
            "Generating train examples...: 47824 examples [00:16, 2833.31 examples/s]\u001b[A\n",
            "Generating train examples...: 48120 examples [00:16, 2867.81 examples/s]\u001b[A\n",
            "Generating train examples...: 48408 examples [00:16, 2836.32 examples/s]\u001b[A\n",
            "Generating train examples...: 48693 examples [00:16, 2600.00 examples/s]\u001b[A\n",
            "Generating train examples...: 48957 examples [00:16, 2565.07 examples/s]\u001b[A\n",
            "Generating train examples...: 49266 examples [00:16, 2710.23 examples/s]\u001b[A\n",
            "Generating train examples...: 49540 examples [00:16, 2690.16 examples/s]\u001b[A\n",
            "Generating train examples...: 49815 examples [00:16, 2706.45 examples/s]\u001b[A\n",
            "Generating train examples...: 50113 examples [00:16, 2783.48 examples/s]\u001b[A\n",
            "Generating train examples...: 50413 examples [00:17, 2845.71 examples/s]\u001b[A\n",
            "Generating train examples...: 50731 examples [00:17, 2943.46 examples/s]\u001b[A\n",
            "Generating train examples...: 51027 examples [00:17, 2925.73 examples/s]\u001b[A\n",
            "Generating train examples...: 51360 examples [00:17, 3043.11 examples/s]\u001b[A\n",
            "Generating train examples...: 51666 examples [00:17, 3047.09 examples/s]\u001b[A\n",
            "Generating train examples...: 51972 examples [00:17, 3050.23 examples/s]\u001b[A\n",
            "Generating train examples...: 52295 examples [00:17, 3103.77 examples/s]\u001b[A\n",
            "Generating train examples...: 52606 examples [00:17, 2990.46 examples/s]\u001b[A\n",
            "Generating train examples...: 52907 examples [00:17, 2949.03 examples/s]\u001b[A\n",
            "Generating train examples...: 53203 examples [00:18, 2938.19 examples/s]\u001b[A\n",
            "Generating train examples...: 53498 examples [00:18, 2898.42 examples/s]\u001b[A\n",
            "Generating train examples...: 53791 examples [00:18, 2906.86 examples/s]\u001b[A\n",
            "Generating train examples...: 54098 examples [00:18, 2953.97 examples/s]\u001b[A\n",
            "Generating train examples...: 54410 examples [00:18, 3002.33 examples/s]\u001b[A\n",
            "Generating train examples...: 54711 examples [00:18, 2961.63 examples/s]\u001b[A\n",
            "Generating train examples...: 55008 examples [00:18, 2841.46 examples/s]\u001b[A\n",
            "Generating train examples...: 55294 examples [00:18, 2728.42 examples/s]\u001b[A\n",
            "Generating train examples...: 55569 examples [00:18, 2731.14 examples/s]\u001b[A\n",
            "Generating train examples...: 55871 examples [00:18, 2813.19 examples/s]\u001b[A\n",
            "Generating train examples...: 56162 examples [00:19, 2840.35 examples/s]\u001b[A\n",
            "Generating train examples...: 56447 examples [00:19, 2835.27 examples/s]\u001b[A\n",
            "Generating train examples...: 56732 examples [00:19, 2789.54 examples/s]\u001b[A\n",
            "Generating train examples...: 57056 examples [00:19, 2920.76 examples/s]\u001b[A\n",
            "Generating train examples...: 57373 examples [00:19, 2991.11 examples/s]\u001b[A\n",
            "Generating train examples...: 57673 examples [00:19, 2975.50 examples/s]\u001b[A\n",
            "Generating train examples...: 57971 examples [00:19, 2976.43 examples/s]\u001b[A\n",
            "Generating train examples...: 58273 examples [00:19, 2988.21 examples/s]\u001b[A\n",
            "Generating train examples...: 58573 examples [00:19, 2555.64 examples/s]\u001b[A\n",
            "Generating train examples...: 58871 examples [00:20, 2667.13 examples/s]\u001b[A\n",
            "Generating train examples...: 59224 examples [00:20, 2903.54 examples/s]\u001b[A\n",
            "Generating train examples...: 59523 examples [00:20, 2924.29 examples/s]\u001b[A\n",
            "Generating train examples...: 59876 examples [00:20, 3095.49 examples/s]\u001b[A\n",
            "Generating train examples...: 60191 examples [00:20, 3089.27 examples/s]\u001b[A\n",
            "Generating train examples...: 60504 examples [00:20, 3004.97 examples/s]\u001b[A\n",
            "Generating train examples...: 60820 examples [00:20, 3048.10 examples/s]\u001b[A\n",
            "Generating train examples...: 61152 examples [00:20, 3127.24 examples/s]\u001b[A\n",
            "Generating train examples...: 61467 examples [00:20, 3044.56 examples/s]\u001b[A\n",
            "Generating train examples...: 61774 examples [00:20, 2997.06 examples/s]\u001b[A\n",
            "Generating train examples...: 62090 examples [00:21, 3043.53 examples/s]\u001b[A\n",
            "Generating train examples...: 62396 examples [00:21, 2984.57 examples/s]\u001b[A\n",
            "Generating train examples...: 62720 examples [00:21, 3058.55 examples/s]\u001b[A\n",
            "Generating train examples...: 63027 examples [00:21, 2989.83 examples/s]\u001b[A\n",
            "Generating train examples...: 63327 examples [00:21, 2691.90 examples/s]\u001b[A\n",
            "Generating train examples...: 63638 examples [00:21, 2805.13 examples/s]\u001b[A\n",
            "                                                                        \u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:   0% 0/63788 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:   2% 1533/63788 [00:00<00:04, 15327.75 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  16% 10519/63788 [00:00<00:00, 59161.24 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  31% 19859/63788 [00:00<00:00, 74791.22 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  47% 29663/63788 [00:00<00:00, 83965.50 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  61% 38745/63788 [00:00<00:00, 86431.40 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  74% 47389/63788 [00:00<00:00, 73421.46 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  86% 55026/63788 [00:00<00:00, 68582.97 examples/s]\u001b[A\n",
            "Shuffling my_dataset-train.tfrecord...:  97% 62110/63788 [00:00<00:00, 56405.58 examples/s]\u001b[A\n",
            "INFO[tfrecords_writer.py]: Done writing my_dataset-train.tfrecord. Number of examples: 63788 (shards: [31894, 31894])\n",
            "Generating splits...:  50% 1/2 [00:22<00:22, 22.71s/ splits]\n",
            "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating test examples...: 278 examples [00:00, 2774.41 examples/s]\u001b[A\n",
            "Generating test examples...: 556 examples [00:00, 2635.61 examples/s]\u001b[A\n",
            "Generating test examples...: 839 examples [00:00, 2719.32 examples/s]\u001b[A\n",
            "Generating test examples...: 1138 examples [00:00, 2822.36 examples/s]\u001b[A\n",
            "Generating test examples...: 1421 examples [00:00, 2807.99 examples/s]\u001b[A\n",
            "Generating test examples...: 1703 examples [00:00, 2767.32 examples/s]\u001b[A\n",
            "Generating test examples...: 1981 examples [00:00, 2750.34 examples/s]\u001b[A\n",
            "Generating test examples...: 2267 examples [00:00, 2783.94 examples/s]\u001b[A\n",
            "Generating test examples...: 2546 examples [00:00, 2772.52 examples/s]\u001b[A\n",
            "Generating test examples...: 2854 examples [00:01, 2865.09 examples/s]\u001b[A\n",
            "Generating test examples...: 3162 examples [00:01, 2930.03 examples/s]\u001b[A\n",
            "Generating test examples...: 3461 examples [00:01, 2945.94 examples/s]\u001b[A\n",
            "Generating test examples...: 3778 examples [00:01, 3010.93 examples/s]\u001b[A\n",
            "Generating test examples...: 4080 examples [00:01, 3007.05 examples/s]\u001b[A\n",
            "Generating test examples...: 4385 examples [00:01, 3017.57 examples/s]\u001b[A\n",
            "Generating test examples...: 4687 examples [00:01, 3016.16 examples/s]\u001b[A\n",
            "Generating test examples...: 4989 examples [00:01, 3000.77 examples/s]\u001b[A\n",
            "Generating test examples...: 5313 examples [00:01, 3071.34 examples/s]\u001b[A\n",
            "Generating test examples...: 5621 examples [00:01, 3049.24 examples/s]\u001b[A\n",
            "Generating test examples...: 5934 examples [00:02, 3071.84 examples/s]\u001b[A\n",
            "Generating test examples...: 6260 examples [00:02, 3125.45 examples/s]\u001b[A\n",
            "Generating test examples...: 6573 examples [00:02, 3075.77 examples/s]\u001b[A\n",
            "Generating test examples...: 6896 examples [00:02, 3120.45 examples/s]\u001b[A\n",
            "Generating test examples...: 7209 examples [00:02, 3030.87 examples/s]\u001b[A\n",
            "Generating test examples...: 7513 examples [00:02, 2980.06 examples/s]\u001b[A\n",
            "Generating test examples...: 7830 examples [00:02, 3033.36 examples/s]\u001b[A\n",
            "Generating test examples...: 8134 examples [00:02, 2953.99 examples/s]\u001b[A\n",
            "Generating test examples...: 8434 examples [00:02, 2964.62 examples/s]\u001b[A\n",
            "Generating test examples...: 8731 examples [00:02, 2956.13 examples/s]\u001b[A\n",
            "Generating test examples...: 9027 examples [00:03, 2956.89 examples/s]\u001b[A\n",
            "Generating test examples...: 9323 examples [00:03, 2952.76 examples/s]\u001b[A\n",
            "Generating test examples...: 9619 examples [00:03, 2908.47 examples/s]\u001b[A\n",
            "Generating test examples...: 9911 examples [00:03, 2875.50 examples/s]\u001b[A\n",
            "Generating test examples...: 10199 examples [00:03, 2795.72 examples/s]\u001b[A\n",
            "Generating test examples...: 10480 examples [00:03, 2763.83 examples/s]\u001b[A\n",
            "Generating test examples...: 10757 examples [00:03, 2396.42 examples/s]\u001b[A\n",
            "Generating test examples...: 11016 examples [00:03, 2445.61 examples/s]\u001b[A\n",
            "Generating test examples...: 11294 examples [00:03, 2536.34 examples/s]\u001b[A\n",
            "Generating test examples...: 11554 examples [00:04, 2551.02 examples/s]\u001b[A\n",
            "Generating test examples...: 11844 examples [00:04, 2649.92 examples/s]\u001b[A\n",
            "Generating test examples...: 12150 examples [00:04, 2767.78 examples/s]\u001b[A\n",
            "Generating test examples...: 12430 examples [00:04, 2674.30 examples/s]\u001b[A\n",
            "Generating test examples...: 12755 examples [00:04, 2839.13 examples/s]\u001b[A\n",
            "Generating test examples...: 13054 examples [00:04, 2882.05 examples/s]\u001b[A\n",
            "Generating test examples...: 13358 examples [00:04, 2927.78 examples/s]\u001b[A\n",
            "Generating test examples...: 13682 examples [00:04, 3017.79 examples/s]\u001b[A\n",
            "Generating test examples...: 13998 examples [00:04, 3057.34 examples/s]\u001b[A\n",
            "Generating test examples...: 14305 examples [00:04, 2990.54 examples/s]\u001b[A\n",
            "Generating test examples...: 14613 examples [00:05, 3015.26 examples/s]\u001b[A\n",
            "Generating test examples...: 14916 examples [00:05, 3006.77 examples/s]\u001b[A\n",
            "Generating test examples...: 15218 examples [00:05, 2943.89 examples/s]\u001b[A\n",
            "Generating test examples...: 15513 examples [00:05, 2929.99 examples/s]\u001b[A\n",
            "Generating test examples...: 15807 examples [00:05, 2890.12 examples/s]\u001b[A\n",
            "                                                                       \u001b[A\n",
            "Shuffling my_dataset-test.tfrecord...:   0% 0/15948 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling my_dataset-test.tfrecord...:  53% 8432/15948 [00:00<00:00, 84310.43 examples/s]\u001b[A\n",
            "INFO[tfrecords_writer.py]: Done writing my_dataset-test.tfrecord. Number of examples: 15948 (shards: [15948])\n",
            "\u001b[1mDataset my_dataset downloaded and prepared to /root/tensorflow_datasets/my_dataset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='my_dataset',\n",
            "    full_name='my_dataset/1.0.0',\n",
            "    description=\"\"\"\n",
            "    This is my demo dataset (description)\n",
            "    \"\"\",\n",
            "    homepage='https://www.tensorflow.org/datasets/catalog/my_dataset',\n",
            "    data_path='/root/tensorflow_datasets/my_dataset/1.0.0',\n",
            "    download_size=Unknown size,\n",
            "    dataset_size=202.67 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(100, 100, 3), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=15948, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=63788, num_shards=2>,\n",
            "    },\n",
            "    citation=\"\"\"@article{my-demo-dataset-2021,\n",
            "                   author = {k3lu},}\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vne8CyMn8_sS"
      },
      "source": [
        "When the dataset include images with various size, we need to resize them into a\n",
        "shared size. The Stanford Dogs dataset includes only images at least 200x200\n",
        "pixels in size. Here we resize the images to the input size needed for EfficientNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SDuTcDDZ8_sR"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "dataset_name = \"my_dataset\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X8yEah-r8_sS"
      },
      "outputs": [],
      "source": [
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPAzQGo88_sT"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "The following code shows the first 9 images with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Fy-5W3Xz8_sT",
        "outputId": "a54d9127-9a4c-4c18-bdcf-94a6fddcfda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-39dcbb3fb2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2329\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/root/tensorflow_datasets/my_dataset/1.0.0/my_dataset-train.tfrecord-00000-of-00002')"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def format_label(label):\n",
        "    string_label = label_info.int2str(label)\n",
        "    return string_label.split(\"-\")[1]\n",
        "\n",
        "\n",
        "label_info = ds_info.features[\"label\"]\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(label))\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSqLMYVe8_sW"
      },
      "source": [
        "### Data augmentation\n",
        "\n",
        "We can use the preprocessing layers APIs for image augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VytWagcU8_sX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        # layers.RandomRotation(factor=0.15),\n",
        "        # layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "        # layers.RandomFlip(),\n",
        "        # layers.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaSZ_AOY8_sX"
      },
      "source": [
        "This `Sequential` model object can be used both as a part of\n",
        "the model we later build, and as a function to preprocess\n",
        "data before feeding into the model. Using them as function makes\n",
        "it easy to visualize the augmented images. Here we plot 9 examples\n",
        "of augmentation result of a given figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sM2kIgyp8_sX",
        "outputId": "3f822b2f-f1ad-48b6-c704-3288db48e82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9d8ed8661d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0maug_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2329\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/root/tensorflow_datasets/my_dataset/1.0.0/my_dataset-train.tfrecord-00000-of-00002')"
          ]
        }
      ],
      "source": [
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
        "        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(label))\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS-X4FJ48_sY"
      },
      "source": [
        "### Prepare inputs\n",
        "\n",
        "Once we verify the input data and augmentation are working correctly,\n",
        "we prepare dataset for training. The input data are resized to uniform\n",
        "`IMG_SIZE`. The labels are put into one-hot\n",
        "(a.k.a. categorical) encoding. The dataset is batched.\n",
        "\n",
        "Note: `prefetch` and `AUTOTUNE` may in some situation improve\n",
        "performance, but depends on environment and the specific dataset used.\n",
        "See this [guide](https://www.tensorflow.org/guide/data_performance)\n",
        "for more information on data pipeline performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gj1wfrPx8_sY",
        "outputId": "919ad4a1-aec5-4493-8f47-0308c0a53d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d2486d53dbe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ds_train = ds_train.map(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minput_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2010\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m           \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5505\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5507\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4533\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4534\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m   3244\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3245\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4509\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4510\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-13-d2486d53dbe4>\", line 3, in input_preprocess  *\n        label = tf.one_hot(label, NUM_CLASSES)\n\n    TypeError: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: uint8, int32, int64\n"
          ]
        }
      ],
      "source": [
        "# One-hot / categorical encoding\n",
        "def input_preprocess(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess)\n",
        "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDmUb7S88_sY"
      },
      "source": [
        "## Training a model from scratch\n",
        "\n",
        "We build an EfficientNetB0 with 120 output classes, that is initialized from scratch:\n",
        "\n",
        "Note: the accuracy will increase very slowly and may overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L8GDqVer8_sZ",
        "outputId": "695b4970-071c-4daa-fecb-bb5d99f3f6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " img_augmentation (Sequentia  multiple                 0         \n",
            " l)                                                              \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 2)                4052133   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,133\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1e34375acbac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m  \u001b[0;31m# @param {type: \"slider\", min:3, max:100}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(8, 100, 100, 3)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "with strategy.scope():\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "    outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 3  # @param {type: \"slider\", min:3, max:100}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGgJOuB78_sZ"
      },
      "source": [
        "Training the model is relatively fast (takes only 20 seconds per epoch on TPUv2 that is\n",
        "available on Colab). This might make it sounds easy to simply train EfficientNet on any\n",
        "dataset wanted from scratch. However, training EfficientNet on smaller datasets,\n",
        "especially those with lower resolution like CIFAR-100, faces the significant challenge of\n",
        "overfitting.\n",
        "\n",
        "Hence training from scratch requires very careful choice of hyperparameters and is\n",
        "difficult to find suitable regularization. It would also be much more demanding in resources.\n",
        "Plotting the training and validation accuracy\n",
        "makes it clear that validation accuracy stagnates at a low value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NXPn3TV8_sZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi85cmeH8_sa"
      },
      "source": [
        "## Transfer learning from pre-trained weights\n",
        "\n",
        "Here we initialize the model with pre-trained ImageNet weights,\n",
        "and we fine-tune it on our own dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SctBYLjL8_sa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHO26eyt8_sa"
      },
      "source": [
        "The first step to transfer learning is to freeze all layers and train only the top\n",
        "layers. For this step, a relatively large learning rate (1e-2) can be used.\n",
        "Note that validation accuracy and loss will usually be better than training\n",
        "accuracy and loss. This is because the regularization is strong, which only\n",
        "suppresses training-time metrics.\n",
        "\n",
        "Note that the convergence may take up to 50 epochs depending on choice of learning rate.\n",
        "If image augmentation layers were not\n",
        "applied, the validation accuracy may only reach ~60%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fWvcB2DN8_sa",
        "outputId": "929dfaac-ba26-4fe5-8704-d76a2ee755b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "996/996 - 280s - loss: 0.6392 - accuracy: 0.7426 - val_loss: 0.4553 - val_accuracy: 0.7733 - 280s/epoch - 281ms/step\n",
            "Epoch 2/4\n",
            "996/996 - 268s - loss: 0.4684 - accuracy: 0.7627 - val_loss: 0.4369 - val_accuracy: 0.7744 - 268s/epoch - 269ms/step\n",
            "Epoch 3/4\n",
            "996/996 - 268s - loss: 0.4554 - accuracy: 0.7662 - val_loss: 0.4352 - val_accuracy: 0.7685 - 268s/epoch - 269ms/step\n",
            "Epoch 4/4\n",
            "996/996 - 268s - loss: 0.4572 - accuracy: 0.7624 - val_loss: 0.4288 - val_accuracy: 0.7747 - 268s/epoch - 269ms/step\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "epochs = 4  # @param {type: \"slider\", min:4, max:80}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n",
        "# plot.hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcSCHAQa8_sb"
      },
      "source": [
        "The second step is to unfreeze a number of layers and fit the model using smaller\n",
        "learning rate. In this example we show unfreezing all layers, but depending on\n",
        "specific dataset it may be desireble to only unfreeze a fraction of all layers.\n",
        "\n",
        "When the feature extraction with\n",
        "pretrained model works good enough, this step would give a very limited gain on\n",
        "validation accuracy. In our case we only see a small improvement,\n",
        "as ImageNet pretraining already exposed the model to a good amount of dogs.\n",
        "\n",
        "On the other hand, when we use pretrained weights on a dataset that is more different\n",
        "from ImageNet, this fine-tuning step can be crucial as the feature extractor also\n",
        "needs to be adjusted by a considerable amount. Such a situation can be demonstrated\n",
        "if choosing CIFAR-100 dataset instead, where fine-tuning boosts validation accuracy\n",
        "by about 10% to pass 80% on `EfficientNetB0`.\n",
        "In such a case the convergence may take more than 50 epochs.\n",
        "\n",
        "A side note on freezing/unfreezing models: setting `trainable` of a `Model` will\n",
        "simultaneously set all layers belonging to the `Model` to the same `trainable`\n",
        "attribute. Each layer is trainable only if both the layer itself and the model\n",
        "containing it are trainable. Hence when we need to partially freeze/unfreeze\n",
        "a model, we need to make sure the `trainable` attribute of the model is set\n",
        "to `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX40Rid28_sb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 10  # @param {type: \"slider\", min:8, max:50}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw2I50oU8_sb"
      },
      "source": [
        "### Tips for fine tuning EfficientNet\n",
        "\n",
        "On unfreezing layers:\n",
        "\n",
        "- The `BathcNormalization` layers need to be kept frozen\n",
        "([more details](https://keras.io/guides/transfer_learning/)).\n",
        "If they are also turned to trainable, the\n",
        "first epoch after unfreezing will significantly reduce accuracy.\n",
        "- In some cases it may be beneficial to open up only a portion of layers instead of\n",
        "unfreezing all. This will make fine tuning much faster when going to larger models like\n",
        "B7.\n",
        "- Each block needs to be all turned on or off. This is because the architecture includes\n",
        "a shortcut from the first layer to the last layer for each block. Not respecting blocks\n",
        "also significantly harms the final performance.\n",
        "\n",
        "Some other tips for utilizing EfficientNet:\n",
        "\n",
        "- Larger variants of EfficientNet do not guarantee improved performance, especially for\n",
        "tasks with less data or fewer classes. In such a case, the larger variant of EfficientNet\n",
        "chosen, the harder it is to tune hyperparameters.\n",
        "- EMA (Exponential Moving Average) is very helpful in training EfficientNet from scratch,\n",
        "but not so much for transfer learning.\n",
        "- Do not use the RMSprop setup as in the original paper for transfer learning. The\n",
        "momentum and learning rate are too high for transfer learning. It will easily corrupt the\n",
        "pretrained weight and blow up the loss. A quick check is to see if loss (as categorical\n",
        "cross entropy) is getting significantly larger than log(NUM_CLASSES) after the same\n",
        "epoch. If so, the initial learning rate/momentum is too high.\n",
        "- Smaller batch size benefit validation accuracy, possibly due to effectively providing\n",
        "regularization.\n",
        "\n",
        "## Using the latest EfficientNet weights\n",
        "\n",
        "Since the initial paper, the EfficientNet has been improved by various methods for data\n",
        "preprocessing and for using unlabelled data to enhance learning results. These\n",
        "improvements are relatively hard and computationally costly to reproduce, and require\n",
        "extra code; but the weights are readily available in the form of TF checkpoint files. The\n",
        "model architecture has not changed, so loading the improved checkpoints is possible.\n",
        "\n",
        "To use a checkpoint provided at\n",
        "[the official model repository](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet), first\n",
        "download the checkpoint. As example, here we download noisy-student version of B1:\n",
        "\n",
        "```\n",
        "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet\\\n",
        "       /noisystudent/noisy_student_efficientnet-b1.tar.gz\n",
        "!tar -xf noisy_student_efficientnet-b1.tar.gz\n",
        "```\n",
        "\n",
        "Then use the script [efficientnet_weight_update_util.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet_weight_update_util.py) to convert ckpt file to h5 file.\n",
        "\n",
        "```\n",
        "!python efficientnet_weight_update_util.py --model b1 --notop --ckpt \\\n",
        "        efficientnet-b1/model.ckpt --o efficientnetb1_notop.h5\n",
        "```\n",
        "\n",
        "When creating model, use the following to load new weight:\n",
        "\n",
        "```python\n",
        "model = EfficientNetB1(weights=\"efficientnetb1_notop.h5\", include_top=False)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification_efficientnet_fine_tuning",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}